{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Rating baseline: compute averages for each user, or return the global average if we've never seen the user before\n",
    "import gzip\n",
    "import random\n",
    "\n",
    "def readGz(f):\n",
    "    for l in gzip.open(f):\n",
    "        yield eval(l)\n",
    "\n",
    "users = set()\n",
    "items = set()\n",
    "set_purchased = []\n",
    "for l in readGz(\"train.json.gz\"):\n",
    "    u,i = l['reviewerID'],l['itemID']\n",
    "    users.add(u)\n",
    "    items.add(i)\n",
    "    set_purchased+=[(u,i)]\n",
    "\n",
    "train_set = set_purchased[:100000]\n",
    "validation_set1 = set_purchased[100000:200000]\n",
    "\n",
    "len_u = len(users)\n",
    "len_i = len(items)\n",
    "\n",
    "# Now randomly generate unpurchased pairs\n",
    "set_unpurchased = set()\n",
    "while(len(set_unpurchased) < 100000):\n",
    "    u = random.sample(users,1)[0]\n",
    "    i = random.sample(items,1)[0]\n",
    "    if (u,i) not in set_purchased:\n",
    "        set_unpurchased.add((u,i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.62918\n"
     ]
    }
   ],
   "source": [
    "#This part is for prediction\n",
    "from collections import defaultdict\n",
    "businessCount = defaultdict(int)\n",
    "totalPurchases = 0\n",
    "\n",
    "for (user,business) in train_set:\n",
    "    businessCount[business] += 1\n",
    "    totalPurchases += 1\n",
    "\n",
    "mostPopular = [(businessCount[x], x) for x in businessCount]\n",
    "mostPopular.sort()\n",
    "mostPopular.reverse()\n",
    "\n",
    "return1 = set()\n",
    "count = 0\n",
    "for ic, i in mostPopular:\n",
    "    count += ic\n",
    "    return1.add(i)\n",
    "    if count > totalPurchases/2: break\n",
    "\n",
    "predictions = []\n",
    "for (u,i) in validation_set1:\n",
    "    if i in return1:\n",
    "        predictions+=[1]\n",
    "    else:\n",
    "        predictions+=[0]\n",
    "\n",
    "for (u,i) in set_unpurchased:\n",
    "    if i in return1:\n",
    "        predictions+=[1]\n",
    "    else:\n",
    "        predictions+=[0]\n",
    "\n",
    "accuracy = (sum([predictions[i] == 1 for i in range(100000)]) + sum([predictions[i] == 0 for i in range(100000,200000)]))/200000\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_set' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-6f9b7f286c77>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtotalPurchases\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbusiness\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mbusinessCount\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbusiness\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mtotalPurchases\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_set' is not defined"
     ]
    }
   ],
   "source": [
    "#Q2:\n",
    "businessCount = defaultdict(int)\n",
    "totalPurchases = 0\n",
    "\n",
    "for (user,business) in train_set:\n",
    "    businessCount[business] += 1\n",
    "    totalPurchases += 1\n",
    "\n",
    "mostPopular = [(businessCount[x], x) for x in businessCount]\n",
    "mostPopular.sort()\n",
    "mostPopular.reverse()\n",
    "\n",
    "return1 = set()\n",
    "count = 0\n",
    "for ic, i in mostPopular:\n",
    "    count += ic\n",
    "    return1.add(i)\n",
    "    if count > totalPurchases/1.9: break\n",
    "\n",
    "predictions = []\n",
    "for (u,i) in validation_set1:\n",
    "    if i in return1:\n",
    "        predictions+=[1]\n",
    "    else:\n",
    "        predictions+=[0]\n",
    "\n",
    "for (u,i) in set_unpurchased:\n",
    "    if i in return1:\n",
    "        predictions+=[1]\n",
    "    else:\n",
    "        predictions+=[0]\n",
    "\n",
    "accuracy = (sum([predictions[i] == 1 for i in range(100000)]) + sum([predictions[i] == 0 for i in range(100000,200000)]))/200000\n",
    "print(\"accuracy\",accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the number is 1.9, the accuracy is higher that in Q1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q3:\n",
    "import gzip\n",
    "from collections import defaultdict\n",
    "\n",
    "def readGz(f):\n",
    "    for l in gzip.open(f):\n",
    "        yield eval(l)\n",
    "train = [l for l in readGz(\"train.json.gz\")][:100000]     \n",
    "training_set = []\n",
    "for l in train:\n",
    "    u,i,c = l['reviewerID'],l['itemID'],l['categoryID']\n",
    "    training_set +=[[u,i,c]]\n",
    "    \n",
    "purchase_history = defaultdict(list)\n",
    "item_cate = defaultdict(int)\n",
    "for l in training_set:\n",
    "    u,i,c = l[0],l[1],l[2]\n",
    "    if c not in purchase_history[u]:\n",
    "        purchase_history[u] += [c]\n",
    "    item_cate[i] = c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted on Kaggle\n"
     ]
    }
   ],
   "source": [
    "#Q4:\n",
    "\n",
    "# predictions = open(\"predictions_Purchase.txt\", 'w')\n",
    "# for l in open(\"pairs_Purchase.txt\"):\n",
    "#     if l.startswith(\"reviewerID\"):\n",
    "#     #header\n",
    "#         predictions.write(\"reviewerID-itemID,prediction\\n\")\n",
    "#         continue\n",
    "#     u,i = l.strip().split('-')\n",
    "#     if item_cate[i] in purchase_history[u]:\n",
    "#         predictions.write(u + '-' + i + \",1\\n\")\n",
    "#     else:\n",
    "#         predictions.write(u + '-' + i + \",0\\n\")\n",
    "        \n",
    "for l in readGz(\"train.json.gz\"):\n",
    "    user,business = l['reviewerID'],l['itemID']\n",
    "    businessCount[business] += 1\n",
    "    totalPurchases += 1\n",
    "\n",
    "mostPopular = [(businessCount[x], x) for x in businessCount]\n",
    "mostPopular.sort()\n",
    "mostPopular.reverse()\n",
    "\n",
    "return1 = set()\n",
    "count = 0\n",
    "for ic, i in mostPopular:\n",
    "    count += ic\n",
    "    return1.add(i)\n",
    "    if count > totalPurchases/1.9: break\n",
    "\n",
    "predictions = open(\"predictions_Purchase.txt\", 'w')\n",
    "for l in open(\"pairs_Purchase.txt\"):\n",
    "    if l.startswith(\"reviewerID\"):\n",
    "    #header\n",
    "        predictions.write(l)\n",
    "        continue\n",
    "    u,i = l.strip().split('-')\n",
    "    if i in return1:\n",
    "        predictions.write(u + '-' + i + \",1\\n\")\n",
    "    else:\n",
    "        predictions.write(u + '-' + i + \",0\\n\")\n",
    "\n",
    "predictions.close()\n",
    "predictions.close()\n",
    "print(\"Submitted on Kaggle\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.73955\n"
     ]
    }
   ],
   "source": [
    "#Q5:\n",
    "import random\n",
    "d = [l for l in readGz(\"train.json.gz\") if 'categoryID' in l][:40000]\n",
    "random.shuffle(d)\n",
    "\n",
    "all_set = []\n",
    "for l in d:\n",
    "    u,i,c = l['reviewerID'],l['itemID'],l['categoryID']\n",
    "    all_set +=[[u,i,c]]\n",
    "\n",
    "train_set = all_set[:20000]\n",
    "validation_set = all_set[20000:40000]\n",
    "\n",
    "sum_cate = [0]*5\n",
    "user_cate = defaultdict(list)\n",
    "item_cate = defaultdict(int)\n",
    "for l in train_set:\n",
    "    u,i,c = l[0],l[1],int(l[2])\n",
    "    if u not in user_cate:\n",
    "        user_cate[u] = [0]*5\n",
    "    user_cate[u][c] += 1\n",
    "    sum_cate[c] += 1\n",
    "    item_cate[i] = c\n",
    "\n",
    "pred_cate = []\n",
    "for l in validation_set:\n",
    "    u,i,c = l[0],l[1],int(l[2])\n",
    "    if u not in user_cate:\n",
    "        pred_cate += [0]\n",
    "    else: \n",
    "        max_cate = max(user_cate[u])\n",
    "        tie = [index for index in range(5) if user_cate[u][index] == max_cate]\n",
    "        if len(tie) == 1:\n",
    "            pred_cate += tie\n",
    "        else: \n",
    "            max_tie = max([sum_cate[i] for i in tie])\n",
    "            pred_cate += [index for index in tie if sum_cate[index] == max_tie]\n",
    "\n",
    "acc = sum([int(validation_set[i][2]) == pred_cate[i] for i in range(len(validation_set))])\n",
    "accuracy = acc/len(validation_set)\n",
    "print(\"accuracy\",accuracy)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Women ['i', 'a', 'it', 'in', 'this', 'but', 'have', 'not', 'them', 'very', 'so', 'was', 'like', 'size', 'wear', 'just', 'comfortable', 'love', 'would', 'its', 'too', 'me', 'more', 'all', 'up', 'nice', 'really', 'am', 'look', 'little', 'im', 'had', 'because', 'get', 'were', 'can', 'dont', 'color', 'ordered', 'perfect', 'shoe', 'do', 'an', 'small', 'also', 'much', 'which', 'looks', 'feet', 'fits', 'long', 'bit', 'even', 'recommend', 'still', 'cute', 'material', 'pretty', 'back', 'bra', 'enough', 'go', 'she', 'day', 'order', 'dress', 'around', 'way', 'think', 'first', 'did', 'could', 'top', 'boots', 'colors', 'foot', 'didnt', 'want', 'black', 'tight', 'down', 'make', 'though', 'style', 'true', 'cant', 'support', 'doesnt', 'worn', 'perfectly', 'expected', 'purchase', 'see', 'going', 'picture', 'definitely', 'wanted', 'wide', 'high', 'beautiful', 'length', 'super', 'give', 'every', 'under', 'thought', 'fine', 'larger', 'medium', 'reviews', 'comfy', 'usually', 'smaller', 'into', 'walking', 'makes', 'actually', 'wore', 'gift', 'cheap', 'came', 'ring', 'short', 'side', 'toe', 'loved', '8', 'wish', 'heel', 'received', 'may', 'try', 'problem', 'white', 'thats', 'return', 'summer', 'ones', 'daughter', 'yet', 'sandals', 'cut', 'narrow', 'inside', 'box', 'straps', 'maybe', 'walk', 'looked', 'boot', 'half', 'normally', 'loose', 'sizes', 'arrived', 'kind', 'bras', 'gave', 'liked', 'everything', 'stretch', 'especially', 'part', '6', 'earrings', 'bag', 'ill', 'able', 'having', 'snug', 'item', 'disappointed', 'toes', 'real', 'compliments', 'others', 'bigger', '7', 'shape', 'such', 'ok', 'leggings', 'strap', '9', 'went', 'absolutely', 'house', 'plus', 'took', 'things', 'silver', 'away', 'stylish', 'shipping', 'bottom', 'ordering', 'arch', 'legs', 'nicely', 'wasnt', 'extremely', 'returned', 'body', 'glad', 'instead', 'fall', 'slip', 'felt', 'brown', 'area', 'already', 'nothing', 'place', 'myself', 'chain', 'piece', 'skirt', 'uncomfortable', 'sexy', 'wife', 'decided', 'someone', 'show', 'havent', 'couldnt', 'goes', 'bracelet', 'runs', 'lightweight', 'red', '1', 'necklace', 'wonderful', 'reason', 'gold', 'between', 'person', 'seller', 'paid']\n",
      "Men ['the', 'and', 'a', 'to', 'is', 'for', 'of', 'they', 'my', 'are', 'these', 'that', 'have', 'with', 'as', 'you', 'fit', 'great', 'be', 'good', 'or', 'well', 'will', 'if', 'more', 'at', 'one', 'shoes', 'nice', 'when', 'than', 'out', 'bought', 'pair', 'from', 'price', 'time', 'quality', 'other', 'about', 'no', 'what', 'your', 'buy', 'has', 'much', 'only', 'got', 'made', 'some', 'after', 'wearing', 'watch', 'material', 'he', 'work', 'big', 'looking', 'shirt', 'right', 'feel', 'socks', 'day', 'there', 'any', 'large', 'been', 'ive', 'now', 'use', 'how', 'better', 'jeans', 'warm', 'find', 'over', 'most', 'does', 'need', 'lot', 'again', 'another', 'purchased', 'pants', 'keep', 'by', 'product', 'however', 'since', 'few', 'two', 'without', 'different', 'same', 'then', 'light', 'know', 'years', 'many', 'while', 'something', 'run', 'who', 'sure', 'always', 'thin', 'new', 'last', 'high', 'theyre', 'amazon', 'never', 'say', 'should', 'easy', 'being', 'we', 'waist', 'husband', 'loves', 'their', '5', 'leather', 'quite', 'weight', 'best', 'band', 'thing', 'used', 'before', 'seems', 'wash', 'buying', 'tried', 'where', 'old', 'found', 'through', 'said', 'year', 'brand', 'belt', 'try', 'those', 'thick', 'needed', 'several', 'thats', 'take', 'money', 'almost', 'might', 'far', 'getting', 'id', 'comfort', 'days', 'ever', 'come', 'both', '10', 'highly', 'his', 'running', 'extra', 'box', 'front', 'feels', 'casual', 'cold', 'months', 'cotton', 'blue', 'bad', 'loose', 'hold', 'wont', 'longer', 'youre', 'people', 'anything', 'liked', 'shirts', 'wears', 'pairs', 'pleased', 'slippers', 'heavy', 'times', 'design', 'winter', 'shorts', 'room', 'cool', 'stars', 'overall', 'couple', 'once', 'low', 'sole', 'excellent', 'works', 'second', 'isnt', 'easily', 'anyone', 'read', 'pockets', 'either', 'own', 'him', 'went', 'wallet', 'set', 'expensive', 'less', 'next', 'awesome', 'jacket', 'here', 'hot', 'dry', 'son', 'slightly', 'regular', 'washed', 'returned', 'why', 'store', 'least', 'expect', 'favorite', 'end', 'wrong', 'watches', 'hat', 'weather', 'water', 'durable', 'nothing', 'quickly', 'wouldnt', 'sturdy', 'says', 'decided', 'tall', 'guess', 'three', 'case', 'type', 'outside', 'christmas', 'ago', 'although', 'normal', 'deal', 'during', 'week', 'keeps']\n",
      "Girls ['and', 'a', 'to', 'it', 'is', 'for', 'of', 'this', 'my', 'on']\n",
      "Boys ['the', 'is', 'for', 'they', 'my', 'are', 'these', 'not', 'them', 'was']\n",
      "Baby ['and', 'to', 'for', 'of', 'in', 'they', 'my', 'are', 'these', 'on']\n"
     ]
    }
   ],
   "source": [
    "#Q6:\n",
    "import string\n",
    "\n",
    "d = [l for l in readGz(\"train.json.gz\") if 'categoryID' in l]\n",
    "train_set = d[:10000]\n",
    "validation_set = d[100000:20000]\n",
    "\n",
    "wordCount = defaultdict(int)\n",
    "count_cat_word = [defaultdict(int),defaultdict(int),defaultdict(int),defaultdict(int),defaultdict(int)]\n",
    "wordCount_cate = defaultdict(int)\n",
    "punctuation = set(string.punctuation)\n",
    "\n",
    "for l in train_set:\n",
    "    r = ''.join([c for c in l['reviewText'].lower() if c not in punctuation])\n",
    "    c = int(l['categoryID'])\n",
    "    for w in r.split():\n",
    "        wordCount[w] +=1\n",
    "        count_cat_word[c][w] += 1 \n",
    "       \n",
    "counts = [(wordCount[w],w) for w in wordCount]\n",
    "counts.sort()\n",
    "counts.reverse()\n",
    "\n",
    "words = [p[1] for p in counts[:500]]\n",
    "# print(words)\n",
    "\n",
    "freq = defaultdict(float)\n",
    "sum_app = sum([p[0] for p in counts[:500]])\n",
    "for w in words:\n",
    "    freq[w] = wordCount[w]/sum_app\n",
    "# print(freq)\n",
    "\n",
    "freq_category = [defaultdict(float),defaultdict(float),defaultdict(float),defaultdict(float),defaultdict(float)]\n",
    "for c in range(5):\n",
    "    for w in words:\n",
    "        freq_category[c][w] = count_cat_word[c][w]/sum([count_cat_word[c][w] for w in words])\n",
    "\n",
    "print(\"Women\",[w for w in words if freq_category[0][w] - freq[w]>0])\n",
    "print(\"Men\",[w for w in words if freq_category[1][w] - freq[w]>0])\n",
    "print(\"Girls\",[w for w in words if freq_category[2][w] - freq[w]>0][:10])\n",
    "print(\"Boys\",[w for w in words if freq_category[3][w] - freq[w]>0][:10])\n",
    "print(\"Baby\",[w for w in words if freq_category[4][w] - freq[w]>0][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: 0.01 accuracy: 0.7902\n",
      "C: 0.1 accuracy: 0.7865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xinyihe/Library/Python/3.7/lib/python/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: 1 accuracy: 0.7853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xinyihe/Library/Python/3.7/lib/python/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: 10 accuracy: 0.7765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xinyihe/Library/Python/3.7/lib/python/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: 100 accuracy: 0.7011\n"
     ]
    }
   ],
   "source": [
    "#Q7:\n",
    "from sklearn import svm\n",
    "\n",
    "d = [l for l in readGz(\"train.json.gz\") if 'categoryID' in l]\n",
    "def feature(l):\n",
    "    feature = []\n",
    "    r = ''.join([c for c in l['reviewText'].lower() if c not in punctuation])\n",
    "    r = r.split()\n",
    "    for w in words:\n",
    "        feature.append(int(w in r))\n",
    "    return feature\n",
    "\n",
    "X_train = [feature(l) for l in d[:10000]]\n",
    "Y_train = [int(l['categoryID']) == 0 for l in d[:10000]]\n",
    "\n",
    "X_validation = [feature(l) for l in d[10000:20000]]\n",
    "Y_validation = [int(l['categoryID']) == 0 for l in d[10000:20000]]\n",
    "\n",
    "for c in [0.01,0.1,1,10,100]:\n",
    "    clf = svm.LinearSVC(C =c)\n",
    "    clf.fit(X_train,Y_train)\n",
    "    train_pred = clf.predict(X_train)\n",
    "    validation_pred = clf.predict(X_validation)\n",
    "    accuracy = sum([Y_validation[i] == validation_pred[i] for i in range(10000)])/10000\n",
    "    print(\"C:\", c,\"accuracy:\",accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When C = 0.01, the binary classifier performs best with an accuracy of 0.7902."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01 0.7807\n",
      "0.1 0.7798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xinyihe/Library/Python/3.7/lib/python/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/xinyihe/Library/Python/3.7/lib/python/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/xinyihe/Library/Python/3.7/lib/python/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.7736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xinyihe/Library/Python/3.7/lib/python/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/xinyihe/Library/Python/3.7/lib/python/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/xinyihe/Library/Python/3.7/lib/python/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/xinyihe/Library/Python/3.7/lib/python/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/xinyihe/Library/Python/3.7/lib/python/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 0.7571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xinyihe/Library/Python/3.7/lib/python/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/xinyihe/Library/Python/3.7/lib/python/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/xinyihe/Library/Python/3.7/lib/python/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/xinyihe/Library/Python/3.7/lib/python/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 0.6945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xinyihe/Library/Python/3.7/lib/python/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "#Q8:\n",
    "from sklearn import svm\n",
    "import numpy\n",
    "\n",
    "X_train = [feature(l) for l in d[:10000]]\n",
    "Y_train = []\n",
    "X_validation = [feature(l) for l in d[10000:20000]]\n",
    "Y_validation = [int(l['categoryID']) for l in d[10000:20000]]\n",
    "\n",
    "for i in range(5):\n",
    "    Y_train.append([int(l['categoryID'])== i for l in d[:10000]])\n",
    "    \n",
    "\n",
    "def classifiers_5(c):\n",
    "    clf = []\n",
    "    Y_pred = []\n",
    "    scores = []\n",
    "    for i in range(5):\n",
    "        clf.append(svm.LinearSVC(C = c))\n",
    "        clf[i].fit(X_train,Y_train[i]) \n",
    "        scores.append(clf[i].decision_function(X_validation))\n",
    "\n",
    "    for j in range(0, 10000):\n",
    "        max_score = max([scores[i][j] for i in range(5)])\n",
    "        for i in range(5):\n",
    "            if scores[i][j] == max_score:\n",
    "                Y_pred.append(i)\n",
    "                break\n",
    "                \n",
    "#     print(Y_pred)\n",
    "    accuracy = sum([Y_pred[j] == Y_validation[j] for j in range(10000)])/10000\n",
    "    print(c, accuracy)\n",
    "\n",
    "\n",
    "classifiers_5(0.01)\n",
    "classifiers_5(0.1)\n",
    "classifiers_5(1)\n",
    "classifiers_5(10)\n",
    "classifiers_5(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose C = 0.01 since it has the highest accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted on Kaggle\n"
     ]
    }
   ],
   "source": [
    "data =[l for l in readGz('test_Category.json.gz')]\n",
    "X_validation = [feature(l) for l in data]\n",
    "    \n",
    "predictions = open(\"predictions_Category.txt\", 'w')\n",
    "predictions.write(\"reviewerID-reviewHash,category\\n\")\n",
    "\n",
    "clf = []\n",
    "Y_pred = []\n",
    "scores = []\n",
    "for i in range(5):\n",
    "    clf.append(svm.LinearSVC(C = 0.01))\n",
    "    clf[i].fit(X_train,Y_train[i]) \n",
    "    scores.append(clf[i].decision_function(X_validation))\n",
    "\n",
    "for j in range(len(X_validation)):\n",
    "    max_score = max([scores[i][j] for i in range(5)])\n",
    "    for i in range(5):\n",
    "        if scores[i][j] == max_score:\n",
    "            Y_pred.append(i)\n",
    "            break\n",
    "\n",
    "for i in range(len(data)):\n",
    "    rid,rh = data[i]['reviewerID'],data[i]['reviewHash']\n",
    "    predictions.write(rid +\"-\"+rh+\",\"+str(Y_pred[i])+\"\\n\")\n",
    "\n",
    "        \n",
    "predictions.close()\n",
    "print(\"Submitted on Kaggle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
